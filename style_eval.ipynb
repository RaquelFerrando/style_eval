{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "load_dotenv(\"key.env\")\n",
    "api_key = os.getenv(\"OPENAI_TOKEN\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "model_imit = \"gpt-4.1\"\n",
    "model_eval = \"gpt-4.1\"\n",
    "\n",
    "#decides if the LLM gets only a fragment of the novel or the complete \n",
    "style_to_imitate = \"book\" #\"fragment\" or \"book\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c432a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract a 4000-words fragment starting from a new paragraph\n",
    "\n",
    "def extract_fragment_from_txt(file_txt, number_of_words=4000):\n",
    "    with open(file_txt, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    #non-empty paragraphs\n",
    "    paragraphs = [p.strip() for p in text.split('\\n') if p.strip()]\n",
    "\n",
    "    max_attempts = 100\n",
    "    for _ in range(max_attempts):\n",
    "        idx_start = random.randint(0, len(paragraphs) - 1)\n",
    "        first_paragraph = paragraphs[idx_start]\n",
    "\n",
    "        #a paragraph should start with a capital letter (in some cases the .txt, as it is generated from a pdf, has 'paragraphs' that start with an incomplete sentence because it was on a new page)\n",
    "        first_char_match = re.search(r'\\S', first_paragraph)  #first char that is not a space\n",
    "        if not first_char_match:\n",
    "            continue  #empty paragraph\n",
    "\n",
    "        first_char = first_char_match.group()\n",
    "        if first_char.isalpha() and first_char.islower():\n",
    "            continue  #not really a new paragraph but a new page\n",
    "\n",
    "        #build the fragment adding paragraphs until 4000 words\n",
    "        fragment = []\n",
    "        total_words = 0\n",
    "\n",
    "        for i in range(idx_start, len(paragraphs)):\n",
    "            paragraph = paragraphs[i]\n",
    "            words = re.findall(r'\\b\\w+\\b', paragraph)\n",
    "            total_words += len(words)\n",
    "            fragment.append(paragraph)\n",
    "            if total_words >= number_of_words:\n",
    "                return '\\n\\n'.join(fragment)\n",
    "\n",
    "    raise ValueError(\"A fragment of the desired number of words (or more) could not be extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f562102",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"SanManuelBuenoMartir.txt\"\n",
    "#\"delfrioalfuego.txt\"\n",
    "#\"los4jinetesdelapocalipsis.txt\" \n",
    "#\"SanManuelBuenoMartir.txt\"\n",
    "#\"tristana_textoplano.txt\"\n",
    "\n",
    "book = file.split('.')[0] #for the name of the excel file\n",
    "\n",
    "fragment = extract_fragment_from_txt(file, number_of_words=4000)\n",
    "print(f\"Length in words: {len(re.findall(r'\\b\\w+\\b', fragment))}\")\n",
    "print(fragment)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM GENERATES A FRAGMENT THAT IMITATES THE STYLE OF THE ORIGINAL ONE (either from the whole novel or one fragment)\n",
    "if style_to_imitate == \"fragment\":\n",
    "    novel_text = fragment\n",
    "else:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        novel_text = f.read()\n",
    "    \n",
    "prompt = (\n",
    "    \"A continuación tienes un texto de una novela. Tienes que escribir un texto en el mismo estilo de unas 4000 palabras. Indica el inicio del fragmento utilizando << y >>. \\n\\n\"\n",
    "    f\"{novel_text}\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model_imit,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Eres un escritor que imita estilos literarios con precisión.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "generated_text = response.choices[0].message.content\n",
    "\n",
    "#extract the fragment between << and >> and count words\n",
    "match = re.search(r'<<(.+?)>>', generated_text, re.DOTALL)\n",
    "if match:\n",
    "    extracted_fragment = match.group(1).strip()\n",
    "    words = re.findall(r'\\b\\w+\\b', extracted_fragment)\n",
    "    word_count = len(words)\n",
    "else:\n",
    "    extracted_fragment = \"\"\n",
    "    word_count = 0\n",
    "\n",
    "#prepare the new row based on the style type\n",
    "if style_to_imitate == \"fragment\":\n",
    "    output_file = f\"{book}.xlsx\"\n",
    "    new_row = pd.DataFrame([{\n",
    "        \"Fragmento\": fragment,\n",
    "        \"Input al modelo\": prompt,\n",
    "        \"Output del modelo\": generated_text,\n",
    "        \"Fragmento generado\": extracted_fragment,\n",
    "        \"Número de palabras\": word_count\n",
    "    }])\n",
    "else:\n",
    "    output_file = f\"{book}_novela_completa.xlsx\"\n",
    "    new_row = pd.DataFrame([{\n",
    "        \"Output del modelo\": generated_text,\n",
    "        \"Fragmento generado\": extracted_fragment,\n",
    "        \"Número de palabras\": word_count\n",
    "    }])\n",
    "\n",
    "#add a new row if the file already exists\n",
    "if os.path.exists(output_file):\n",
    "    df_existing = pd.read_excel(output_file)\n",
    "    df_combined = pd.concat([df_existing, new_row], ignore_index=True)\n",
    "else:\n",
    "    df_combined = new_row\n",
    "\n",
    "#save the updated file\n",
    "df_combined.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab182c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE ASSISTANT FOR EVALUATION (only once)\n",
    "# Check if assistant ID is saved\n",
    "assistant_file = \"assistant_id.json\"\n",
    "\n",
    "if os.path.exists(assistant_file):\n",
    "    # Load existing assistant ID\n",
    "    with open(assistant_file, \"r\") as f:\n",
    "        assistant_id = json.load(f)[\"assistant_id\"]\n",
    "else: \n",
    "    # Create assistant only once\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"Evaluador de estilos de novelas\",\n",
    "        instructions=\"Eres un crítico literario especializado en analizar el estilo narrativo de novelas. Tu tarea es examinar textos y ofrecer una evaluación detallada del estilo, incluyendo tono, estructura, uso del lenguaje, ritmo y voz narrativa.\",\n",
    "        model=model_eval\n",
    "    )\n",
    "    assistant_id = assistant.id\n",
    "    # Save to file\n",
    "    with open(assistant_file, \"w\") as f:\n",
    "        json.dump({\"assistant_id\": assistant_id}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1150be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Create a thread (new conversation) \n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "#2) Prompt\n",
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=(\n",
    "        \"A continuación tienes dos textos, etiquetados como TEXTO 1 y TEXTO 2. Quiero que evalúes si tienen el mismo estilo y podrían haber sido escritos por la misma persona. \"\n",
    "        \"Razona en detalle tu respuesta y devuelve el resultado final en formato: <<RESULTADO FINAL: SÍ>> o <<RESULTADO FINAL: NO>>.\\n\\n\"\n",
    "        f\"TEXTO 1:\\n{fragment}\\n\\n\"\n",
    "        f\"TEXTO 2:\\n{extracted_fragment}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "#3) the assistant answers\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id\n",
    ")\n",
    "\n",
    "#4) Wait\n",
    "while True:\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    if run_status.status == \"completed\":\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# 5) Obtain answer of the assistant\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "assistant_reply = messages.data[0].content[0].text.value  \n",
    "\n",
    "# 6) Extract final result\n",
    "if \"RESULTADO FINAL: SÍ\" in assistant_reply:\n",
    "    final_result = \"SÍ\"\n",
    "else:\n",
    "    final_result = \"NO\"\n",
    "\n",
    "# 7) If the result is NO, ask for a better prompt\n",
    "if final_result == \"NO\":\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\", \n",
    "        content=\"El TEXTO 2 es una imitación del estilo del TEXTO 1 generada por un LLM, a partir del prompt \\\"A continuación tienes un texto de una novela. Tienes que escribir un texto en el mismo estilo de unas 4000 palabras. Indica el inicio del fragmento utilizando << y >>.\\\"\"\n",
    "                \"Teniendo en cuenta los problemas que has detectado en el TEXTO 2, proporciona un prompt mejorado, dándole indicaciones adicionales sobre el estilo que debe adoptar. Usa << y >> para indicar el principio y el final del nuevo prompt.\"\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant_id\n",
    "    )\n",
    "\n",
    "    #\n",
    "    while True:\n",
    "        run_status = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        if run_status.status == \"completed\":\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    nueva_respuesta = messages.data[0].content[0].text.value\n",
    "    print(\"Prompt sugerido:\\n\", nueva_respuesta)\n",
    "\n",
    "else:\n",
    "    print(\"Resultado final del análisis:\", final_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
